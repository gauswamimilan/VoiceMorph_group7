{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_george_0.wav',\n",
       " '0_george_1.wav',\n",
       " '0_george_10.wav',\n",
       " '0_george_11.wav',\n",
       " '0_george_12.wav']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_wrd = os.getcwd()\n",
    "dataset_path = os.path.join(current_wrd, 'recordings')\n",
    "dataset_files = os.listdir(dataset_path)\n",
    "dataset_files[:5]\n",
    "# {digitLabel}_{speakerName}_{index}.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"file\": dataset_files})\n",
    "df[\"length\"] = df[\"file\"].apply(lambda x: librosa.core.load(os.path.join(dataset_path, x), sr=8000)[0].shape[0])\n",
    "df[\"number\"] = df[\"file\"].apply(lambda x: x.split(\"_\")[0])\n",
    "df[\"speaker\"] = df[\"file\"].apply(lambda x: x.split(\"_\")[1])\n",
    "df[\"index\"] = df[\"file\"].apply(lambda x: x.split(\"_\")[2].split(\".\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3135    6\n",
       "3599    6\n",
       "3410    6\n",
       "3355    5\n",
       "2936    5\n",
       "       ..\n",
       "1433    1\n",
       "2837    1\n",
       "1403    1\n",
       "1634    1\n",
       "3507    1\n",
       "Name: length, Length: 2056, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>S</th>\n",
       "      <th>y</th>\n",
       "      <th>sr</th>\n",
       "      <th>ref_value</th>\n",
       "      <th>S_db</th>\n",
       "      <th>number</th>\n",
       "      <th>speaker</th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_george_0.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>george</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_george_1.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>george</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_george_10.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>george</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_george_11.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>george</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_george_12.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>george</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>9_yweweler_5.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>9_yweweler_6.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>9_yweweler_7.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>9_yweweler_8.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>9_yweweler_9.wav</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file     S     y    sr ref_value  S_db number   speaker  \\\n",
       "0       0_george_0.wav  None  None  None      None  None      0    george   \n",
       "1       0_george_1.wav  None  None  None      None  None      0    george   \n",
       "2      0_george_10.wav  None  None  None      None  None      0    george   \n",
       "3      0_george_11.wav  None  None  None      None  None      0    george   \n",
       "4      0_george_12.wav  None  None  None      None  None      0    george   \n",
       "...                ...   ...   ...   ...       ...   ...    ...       ...   \n",
       "2995  9_yweweler_5.wav  None  None  None      None  None      9  yweweler   \n",
       "2996  9_yweweler_6.wav  None  None  None      None  None      9  yweweler   \n",
       "2997  9_yweweler_7.wav  None  None  None      None  None      9  yweweler   \n",
       "2998  9_yweweler_8.wav  None  None  None      None  None      9  yweweler   \n",
       "2999  9_yweweler_9.wav  None  None  None      None  None      9  yweweler   \n",
       "\n",
       "     index  target  \n",
       "0        0       0  \n",
       "1        1       0  \n",
       "2       10       0  \n",
       "3       11       0  \n",
       "4       12       0  \n",
       "...    ...     ...  \n",
       "2995     5       0  \n",
       "2996     6       0  \n",
       "2997     7       0  \n",
       "2998     8       0  \n",
       "2999     9       0  \n",
       "\n",
       "[3000 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6571,) (20,13) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\Speech Processing\\Project\\AudioMnist\\classical.ipynb Cell 6\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m george_mfcc_norm \u001b[39m=\u001b[39m (george_mfcc \u001b[39m-\u001b[39m george_mean) \u001b[39m/\u001b[39m george_std\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#applying the normalization to the michael audio\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m michael_audio_norm \u001b[39m=\u001b[39m michael_audio \u001b[39m*\u001b[39;49m michael_mfcc_norm\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#synthesizing the audio\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m george_audio_norm \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39msynthesize(george_mfcc_norm, george_sr)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6571,) (20,13) "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "source_file = os.path.join(dataset_path, \"0_george_0.wav\")\n",
    "target_file = os.path.join(dataset_path, \"0_lucas_0.wav\")\n",
    "\n",
    "#loading the audio files\n",
    "michael_audio, michael_sr = librosa.load(source_file)\n",
    "george_audio, george_sr = librosa.load(target_file)\n",
    "\n",
    "#extracting the mfcc features\n",
    "michael_mfcc = librosa.feature.mfcc(y=michael_audio, sr=michael_sr)\n",
    "george_mfcc = librosa.feature.mfcc(y=george_audio, sr=george_sr)\n",
    "\n",
    "#calculating the mean and standard deviation of the mfcc features\n",
    "michael_mean = np.mean(michael_mfcc, axis=1)[0]\n",
    "michael_std = np.std(michael_mfcc, axis=1)[0]\n",
    "george_mean = np.mean(george_mfcc, axis=1)[0]\n",
    "george_std = np.std(george_mfcc, axis=1)[0]\n",
    "\n",
    "#normalizing the mfcc features\n",
    "michael_mfcc_norm = (michael_mfcc - michael_mean) / michael_std\n",
    "george_mfcc_norm = (george_mfcc - george_mean) / george_std\n",
    "\n",
    "#applying the normalization to the michael audio\n",
    "michael_audio_norm = michael_audio * michael_mfcc_norm\n",
    "\n",
    "#synthesizing the audio\n",
    "george_audio_norm = librosa.core.synthesize(george_mfcc_norm, george_sr)\n",
    "\n",
    "#saving the audio\n",
    "output_file = 'output_file_0_lucas_0.wav'\n",
    "\n",
    "sf.write(output_file, george_audio_norm, george_sr, subtype='PCM_24')\n",
    "# librosa.output.write_wav('george_voice.wav', george_audio_norm, george_sr)\n",
    "\n",
    "#printing the output\n",
    "print('Voice conversion successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No librosa attribute hz_to_semitone",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\Speech Processing\\Project\\AudioMnist\\classical.ipynb Cell 7\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m target_pitch \u001b[39m=\u001b[39m target_pitch[:,\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Resample the source audio file to match the target pitch\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m output_audio \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39meffects\u001b[39m.\u001b[39mpitch_shift(y\u001b[39m=\u001b[39msource, sr\u001b[39m=\u001b[39msr, n_steps\u001b[39m=\u001b[39mlibrosa\u001b[39m.\u001b[39;49mhz_to_semitone(target_pitch\u001b[39m/\u001b[39msource_pitch), bins_per_octave\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Write the output to a file\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Speech%20Processing/Project/AudioMnist/classical.ipynb#W0sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m output_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39moutput_file_pitch_scaling.wav\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32md:\\PythonEnvs\\anaconda3\\envs\\venv\\lib\\site-packages\\lazy_loader\\__init__.py:88\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m attr\n\u001b[0;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo \u001b[39m\u001b[39m{\u001b[39;00mpackage_name\u001b[39m}\u001b[39;00m\u001b[39m attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: No librosa attribute hz_to_semitone"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Load the source and target audio files\n",
    "source_file = os.path.join(dataset_path, \"0_george_0.wav\")\n",
    "target_file = os.path.join(dataset_path, \"0_lucas_0.wav\")\n",
    "source, sr = librosa.load(source_file)\n",
    "target, _ = librosa.load(target_file, sr=sr, duration=len(source)/sr)\n",
    "\n",
    "# Compute the LPC coefficients of the source audio file\n",
    "order = 12\n",
    "lpc_coeffs = librosa.lpc(y=source, order=order)\n",
    "\n",
    "# 1. Spectral Envelope Transfer\n",
    "# Compute the spectral envelope of the target audio file\n",
    "target_spectrum = librosa.stft(y=target)\n",
    "target_magnitude, target_phase = librosa.magphase(target_spectrum)\n",
    "target_spectrum_envelope = librosa.amplitude_to_db(target_magnitude)\n",
    "\n",
    "# Apply the spectral envelope of the target audio file to the source audio file\n",
    "source_spectrum = librosa.stft(y=source)\n",
    "source_magnitude, source_phase = librosa.magphase(source_spectrum)\n",
    "output_spectrum = librosa.db_to_amplitude(target_spectrum_envelope) * source_phase\n",
    "output_audio = librosa.istft(output_spectrum, length=len(source))\n",
    "\n",
    "# Write the output to a file\n",
    "output_file = 'output_file_spectral_envelope_transfer.wav'\n",
    "sf.write(output_file, output_audio, sr)\n",
    "\n",
    "# 2. Pitch Scaling\n",
    "# Compute the pitch of the source audio file\n",
    "source_pitch, _ = librosa.core.piptrack(y=source, sr=sr)\n",
    "source_pitch = source_pitch[:,0]\n",
    "\n",
    "# Compute the pitch of the target audio file\n",
    "target_pitch, _ = librosa.core.piptrack(y=target, sr=sr)\n",
    "target_pitch = target_pitch[:,0]\n",
    "\n",
    "# Resample the source audio file to match the target pitch\n",
    "output_audio = librosa.effects.pitch_shift(y=source, sr=sr, n_steps=librosa.hz_to_semitone(target_pitch/source_pitch), bins_per_octave=12)\n",
    "\n",
    "# Write the output to a file\n",
    "output_file = 'output_file_pitch_scaling.wav'\n",
    "sf.write(output_file, output_audio, sr)\n",
    "\n",
    "# 3. Formant Shifting\n",
    "# Compute the formants (resonant frequencies) of the source audio file\n",
    "roots = np.roots(lpc_coeffs)\n",
    "angles = np.angle(roots)\n",
    "freqs = angles * (sr / (2 * np.pi))\n",
    "sorted_freqs = np.sort(freqs)\n",
    "\n",
    "# Compute the target formants (e.g., the formants of the target speaker)\n",
    "target_formants = [800, 1200, 2800]  # Replace with the desired target formants\n",
    "\n",
    "# Modify the formants of the source audio file to match the target formants\n",
    "shifted_roots = np.exp(1j * 2 * np.pi * np.array(target_formants) / sr)\n",
    "shifted_coeffs = np.poly(shifted_roots)\n",
    "shifted_audio = librosa.lfilter(b=shifted_coeffs, a=[1], x=source)\n",
    "\n",
    "# Write the output to a file\n",
    "output_file = 'output_file_formant_shifting.wav'\n",
    "sf.write(output_file, shifted_audio, sr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
